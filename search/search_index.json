{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Course Information Schedule Week Date Topic Test 1. Sept 6 Requirements. ROS introduction. Setup the development environment. - 2. Sept 13 Setup the development environment. Linux principles. ROS principles. Running examples. ROS package. Basics of ROS communication, implementation of publisher and subscriber. Project topic announcements. 3. Sept 20 Python principles. Practicing ROS communication, solving examples. - 5. Oct 4 Principles of robotics. Programming a da Vinci surgical robot in simulated environment I. - 6. Oct 11 Principles of robotics. Programming a da Vinci surgical robot in simulated environment II. Test 1 : ROS princiles, publisher, subscriber. Python principles. Principles of robotics. 7. Oct 18 Versioning, Git. Project labor I. - 8. Oct 25 Roslaunch, ROS parameter server. Rosbag. - 10. Nov 8 Kinematics, inverse kinematics, programming a simulated robot arm in joint space and workspace I. - 11. Nov 15 Kinematics, inverse kinematics, programming a simulated robot arm in joint space and workspace II. - 13. Nov 29 Project labor II. - 14. Nov 6 - Project presentations. Retake. Test 2 : Roslaunch, ROS parameter server. ROS service. ROS action. Kinematics, inverse kinematics. Warning The schedule may change during the semester! Course Requirements Project Proved to be the student's own work Running results valid output Grading: completeness of the soultion, proper ROS communication, proper structure of the program, quality of implementation, documentation Grading Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Jegy = (Test1 + Test2 + 2 \\times Project) / 4\\) Course Supervisor Dr. P\u00e9ter Galambos peter.galambos@irob.uni-obuda.hu Teachers Tam\u00e1s D. Nagy tamas.daniel.nagy@irob.uni-obuda.hu Borsa D\u00e9t\u00e1r detar.borsa@gmail.com Antal Bejczy Center for Intelligent Robotics (BARK/IROB) https://irob.uni-obuda.hu irob-saf (iRob Surgical Automation Framework) https://github.com/ABC-iRobotics/irob-saf PlatypOUs https://github.com/ABC-iRobotics/PlatypOUs-Mobile-Robot-Platform","title":"Home"},{"location":"#course-information","text":"","title":"Course Information"},{"location":"#schedule","text":"Week Date Topic Test 1. Sept 6 Requirements. ROS introduction. Setup the development environment. - 2. Sept 13 Setup the development environment. Linux principles. ROS principles. Running examples. ROS package. Basics of ROS communication, implementation of publisher and subscriber. Project topic announcements. 3. Sept 20 Python principles. Practicing ROS communication, solving examples. - 5. Oct 4 Principles of robotics. Programming a da Vinci surgical robot in simulated environment I. - 6. Oct 11 Principles of robotics. Programming a da Vinci surgical robot in simulated environment II. Test 1 : ROS princiles, publisher, subscriber. Python principles. Principles of robotics. 7. Oct 18 Versioning, Git. Project labor I. - 8. Oct 25 Roslaunch, ROS parameter server. Rosbag. - 10. Nov 8 Kinematics, inverse kinematics, programming a simulated robot arm in joint space and workspace I. - 11. Nov 15 Kinematics, inverse kinematics, programming a simulated robot arm in joint space and workspace II. - 13. Nov 29 Project labor II. - 14. Nov 6 - Project presentations. Retake. Test 2 : Roslaunch, ROS parameter server. ROS service. ROS action. Kinematics, inverse kinematics. Warning The schedule may change during the semester!","title":"Schedule"},{"location":"#course-requirements","text":"","title":"Course Requirements"},{"location":"#project","text":"Proved to be the student's own work Running results valid output Grading: completeness of the soultion, proper ROS communication, proper structure of the program, quality of implementation, documentation","title":"Project"},{"location":"#grading","text":"Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Jegy = (Test1 + Test2 + 2 \\times Project) / 4\\)","title":"Grading"},{"location":"#course-supervisor","text":"Dr. P\u00e9ter Galambos peter.galambos@irob.uni-obuda.hu","title":"Course Supervisor"},{"location":"#teachers","text":"Tam\u00e1s D. Nagy tamas.daniel.nagy@irob.uni-obuda.hu Borsa D\u00e9t\u00e1r detar.borsa@gmail.com","title":"Teachers"},{"location":"#antal-bejczy-center-for-intelligent-robotics-barkirob","text":"https://irob.uni-obuda.hu","title":"Antal Bejczy Center for Intelligent Robotics (BARK/IROB)"},{"location":"#irob-saf","text":"(iRob Surgical Automation Framework) https://github.com/ABC-iRobotics/irob-saf","title":"irob-saf"},{"location":"#platypous","text":"https://github.com/ABC-iRobotics/PlatypOUs-Mobile-Robot-Platform","title":"PlatypOUs"},{"location":"01_intro/","text":"01. Introduction Robot Operating System (ROS) introduction The definition of robot Joseph Engelberger, pioneer in industrial robotics: \"I can't define a robot, but I know one when I see one.\" Wikipedia: \"A robot is a machine\u2014especially one programmable by a computer\u2014 capable of carrying out a complex series of actions automatically. Robots can be guided by an external control device or the control may be embedded within. Robots may be constructed on the lines of human form, but most robots are machines designed to perform a task with no regard to their aesthetics.\" ISO 8373:2012 Robots and robotic devices \u2013 Vocabulary, FDIS 2012: \"A robot is an actuated mechanism programmable in two or more axes with a degree of autonomy, moving within its environment, to perform intended tasks.\" Rodney Brooks, Founder and CTO, Rethink Robotics: \"A robot is some sort of device, wich has sensors those sensors the world, does some sort of computation, decides on an action, and then does that action based on the sensory input, which makes some change out in the world, outside its body. Comment: the part \"make some change outside its body\" discriminates a washing machine from e.g. a Roomba.\" Tam\u00e1s Haidegger, Encyclopedia of Robotics : \"A robot is a complex mechatronic system enabled with electronics, sensors, actuators and software, executing tasks with a certain degree of autonomy. It may be pre-programmed, teleoperated or carrying out computations to make decisions.\" What is ROS? Open-source, robotics themed middleware Modularity, reusability (drivers, algorithms, libraries, ...) Hardware abstraction, ROS API C++ \u00e9s Python support Ubuntu Linux (except ROS 2) Great community History Mid 2000s, Stanford: robotics themed, flexible, dynamic framework for prototype development 2007, Willow Garage: incubation, the core of ROS under BSD license Spread in robotics reserach, PR2 2012: Industrial robotics, ROS-Industrial 2017: ROS 2 Development system build -- homework Recommended environment: Ubuntu 20.04 ROS Noetic IDE: QtCreator ROS sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 sudo apt update sudo apt install ros-noetic-desktop-full source /opt/ros/noetic/setup.bash The command source is responsible for setting environmental variables, and it has to be executed every time a new terminal window is opened. Alternatively, this command can be copied to the end of the file ~/.bashrc . This script runs automatically every time when a terinal window is opened. To do that, type: echo \"source /opt/ros/noetic/setup.bash\" >> ~/.bashrc source ~/.bashrc ROS dependencies sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential sudo rosdep init rosdep update Then test our ROS install by typing: roscore Further packages The following packages are also going to be needed during the course, so it is recommended to install them: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-catkin-tools python3-osrf-pycommon libasound2-dev libgl1-mesa-dev xorg-dev QtCreator For the purpose of the development of ROS packages QtCreator is one of the best IDEs, a ROS plugin is also available for that. The one for Ubuntu 18.04 also works on 20.04, thus one can use the Bionic Offline Installer. It can be downloaded from the following link: https://ros-qtc-plugin.readthedocs.io/en/latest/_source/How-to-Install-Users.html After the installer is downloaded, the IDE can be installed by the following command (important to navigate to the location of the download using cd : sudo ./qtcreator-ros-bionic-latest-online-installer.run When the installer asks for a location to install, modify it to the /home/<USER>/QtCreator folder, and not to root. After installing, the IDE can be find with the name \"Qt Creator (4.9.2)\" Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator Links https://www.ros.org/ https://www.ros.org/install/ http://wiki.ros.org/ROS/Tutorials Markdown Cheatsheet Online MD editor: HackMD QtCreator + ROS plugin IROB virtual tour ROS 10 years montage","title":"1. Introduction"},{"location":"01_intro/#01-introduction","text":"","title":"01. Introduction"},{"location":"01_intro/#robot-operating-system-ros-introduction","text":"","title":"Robot Operating System (ROS) introduction"},{"location":"01_intro/#the-definition-of-robot","text":"Joseph Engelberger, pioneer in industrial robotics: \"I can't define a robot, but I know one when I see one.\" Wikipedia: \"A robot is a machine\u2014especially one programmable by a computer\u2014 capable of carrying out a complex series of actions automatically. Robots can be guided by an external control device or the control may be embedded within. Robots may be constructed on the lines of human form, but most robots are machines designed to perform a task with no regard to their aesthetics.\" ISO 8373:2012 Robots and robotic devices \u2013 Vocabulary, FDIS 2012: \"A robot is an actuated mechanism programmable in two or more axes with a degree of autonomy, moving within its environment, to perform intended tasks.\" Rodney Brooks, Founder and CTO, Rethink Robotics: \"A robot is some sort of device, wich has sensors those sensors the world, does some sort of computation, decides on an action, and then does that action based on the sensory input, which makes some change out in the world, outside its body. Comment: the part \"make some change outside its body\" discriminates a washing machine from e.g. a Roomba.\" Tam\u00e1s Haidegger, Encyclopedia of Robotics : \"A robot is a complex mechatronic system enabled with electronics, sensors, actuators and software, executing tasks with a certain degree of autonomy. It may be pre-programmed, teleoperated or carrying out computations to make decisions.\"","title":"The definition of robot"},{"location":"01_intro/#what-is-ros","text":"Open-source, robotics themed middleware Modularity, reusability (drivers, algorithms, libraries, ...) Hardware abstraction, ROS API C++ \u00e9s Python support Ubuntu Linux (except ROS 2) Great community","title":"What is ROS?"},{"location":"01_intro/#history","text":"Mid 2000s, Stanford: robotics themed, flexible, dynamic framework for prototype development 2007, Willow Garage: incubation, the core of ROS under BSD license Spread in robotics reserach, PR2 2012: Industrial robotics, ROS-Industrial 2017: ROS 2","title":"History"},{"location":"01_intro/#development-system-build-homework","text":"Recommended environment: Ubuntu 20.04 ROS Noetic IDE: QtCreator ROS sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 sudo apt update sudo apt install ros-noetic-desktop-full source /opt/ros/noetic/setup.bash The command source is responsible for setting environmental variables, and it has to be executed every time a new terminal window is opened. Alternatively, this command can be copied to the end of the file ~/.bashrc . This script runs automatically every time when a terinal window is opened. To do that, type: echo \"source /opt/ros/noetic/setup.bash\" >> ~/.bashrc source ~/.bashrc ROS dependencies sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential sudo rosdep init rosdep update Then test our ROS install by typing: roscore Further packages The following packages are also going to be needed during the course, so it is recommended to install them: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-catkin-tools python3-osrf-pycommon libasound2-dev libgl1-mesa-dev xorg-dev QtCreator For the purpose of the development of ROS packages QtCreator is one of the best IDEs, a ROS plugin is also available for that. The one for Ubuntu 18.04 also works on 20.04, thus one can use the Bionic Offline Installer. It can be downloaded from the following link: https://ros-qtc-plugin.readthedocs.io/en/latest/_source/How-to-Install-Users.html After the installer is downloaded, the IDE can be installed by the following command (important to navigate to the location of the download using cd : sudo ./qtcreator-ros-bionic-latest-online-installer.run When the installer asks for a location to install, modify it to the /home/<USER>/QtCreator folder, and not to root. After installing, the IDE can be find with the name \"Qt Creator (4.9.2)\" Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator","title":"Development system build -- homework"},{"location":"01_intro/#links","text":"https://www.ros.org/ https://www.ros.org/install/ http://wiki.ros.org/ROS/Tutorials Markdown Cheatsheet Online MD editor: HackMD QtCreator + ROS plugin IROB virtual tour ROS 10 years montage","title":"Links"},{"location":"02_linux_ros_principles/","text":"02. Linux and ROS principles Lecture Linux principles Only OS supported by ROS Security Efficieny Open-source Community support User freedom Distributions: Ubuntu , Linux Mint, Debian, etc. Terminal usage more dominant Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator Linux commands See some basic commands below: Run as administrator with sudo Manual of command man , e.g. man cp Package management apt , e.g. apt update , apt install Navigation cd List directory contents ls Copy file cp Move file mv Remove file rm Make directory mkdir Remove directory rmdir Make a file executable chmod +x <filename> Safe restart: Crtl + Alt + PrtScr + REISUB If not sure, just google the command ROS principles ROS file system ROS package principle Enough functionality to be useful, but not too much that the package is heavyweight and difficult to use from other software. ROS package Main unit to organize software in ROS Buildable and redistributable unit of ROS code Consosts of: Manifest (package.xml): information about package name version description dependencies etc. CMakeLists.txt: input for the CMake build system Anything else rosrun turtlesim turtlesim_node ROS node Executable part of ROS: python scripts compiled C++ code A process that performs computation Inter-node communication: ROS topics (streams) ROS parameter server Remote Procedure Calls (RPC) ROS services ROS actions Meant to operate at a fine-grained scale Typically, a robot control system consists of many nodes, like: Trajectory planning Localization Read sensory data Process sensory data Motor control User interface etc. ROS build system---Catkin System for building software packages in ROS ROS workspace Catkin workspace A folder where catkin packages are modified, built, and installed. Source space: Source code of catkin packages Space where you can extract/checkout/clone source code for the packages you want to build Build space CMake is invoked here to build the catkin packages CMake and catkin keep intermediate files here Devel space: Built target are placed here prior to being installed Environmental setup file setup.bash generated during init process of a new workspace extends shell environment ROS can find any resources that have been installed or built to that location source ~/catkin_ws/devel/setup.bash ROS master roscore Registers: Nodes Topics Services Parameters One per system roslaunch launches ROS master automatically Gyakorlat Warning! At the end of the lesson, everybody must upload their sources to Moodle as a zip archive! 1: Turtlesim Launch ROS master, turtlesim_node and turtle_teleop_key node by typing the following commands to separate terminal windows: Tip In Terminator , Ctrl-Shift-O , Ctrl-Shift-E divides the terimal window, Ctrl-Shift-W closes the current window. roscore rosrun turtlesim turtlesim_node rosrun turtlesim turtle_teleop_key To stup running Ctrl-C Display the running nodes and topics using this command, in a separate terminal: rosrun rqt_graph rqt_graph Try the following commands to gain more information about the currently running system: roswtf rospack list rospack find turtlesim rosnode list rosnode info rosnode info /turtlesim rostopic list rostopic info /turtle1/cmd_vel rosmsg show geometry_msgs/Twist rostopic echo /turtle1/cmd_vel Type (or copy) the following command to the terminal: rostopic pub /turtle1/cmd_vel geometry_msgs/Twist -r 1 -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]' 2: Catkin workspace Install the catkin build tools package: sudo apt update sudo apt-get install python3-catkin-tools python3-osrf-pycommon Copy the follwoing file to the end of file ~/.bashrc : source /opt/ros/noetic/setup.bash # replace noetic by whatever your ROS distribution is Create the workspace: source /opt/ros/noetic/setup.bash mkdir -p ~/catkin_ws/src cd ~/catkin_ws catkin init 3: Create a new ROS package Create a new ROS package named ros_course , depends packages std_msgs , rospy and roscpp : cd ~/catkin_ws/src catkin create pkg ros_course --catkin-deps std_msgs rospy roscpp Syntax catkin create pkg <PKG_NAME> --catkin-deps <DEP_1> <DEP_2> Open the file package.xml and fill the following tags: <description> The beginner_tutorials package </description> <maintainer email= \"you@yourdomain.tld\" > Your Name </maintainer> Build the workspace: cd ~/catkin_ws catkin build Danger The commands catkin build and catkin_make are not meant to be used within the same workspace! Append the following line to the file ~/.bashrc : source ~/catkin_ws/devel/setup.bash 4: Implement a Publisher in Python Create folder named scripts in the ros_course package: cd ~/catkin_ws/src/ros_course mkdir scripts cd scripts Navigate to the scripts folder and create the file talker.py , fill it with the following content: import rospy from std_msgs.msg import String def talker (): rospy . init_node ( 'talker' , anonymous = True ) pub = rospy . Publisher ( 'chatter' , String , queue_size = 10 ) rate = rospy . Rate ( 10 ) # 10hz while not rospy . is_shutdown (): hello_str = \"hello world %s \" % rospy . get_time () print ( hello_str ) pub . publish ( hello_str ) rate . sleep () if __name__ == '__main__' : try : talker () except rospy . ROSInterruptException : pass Open CMakeLists.txt and find the commented out line starting with catkin_install_python (it is near line 167). Uncomment and edit as the following: catkin_install_python ( PROGRAMS scripts/talker.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Build the node: cd ~/catkin_ws catkin build Start ROS master and run the node. In separate terminal windows: roscore rosrun ros_course talker.py Check the output of the node, in a separate terminal: rostopic echo chatter 5: Implement a Subscriber in Python Navigate to the scripts folder and create the file listener.py : import rospy from std_msgs.msg import String def callback ( data ): print ( rospy . get_caller_id () + \"I heard \" + data . data ) def listener (): # In ROS, nodes are uniquely named. If two nodes with the same # name are launched, the previous one is kicked off. The # anonymous=True flag means that rospy will choose a unique # name for our 'listener' node so that multiple listeners can # run simultaneously. rospy . init_node ( 'listener' , anonymous = True ) rospy . Subscriber ( \"chatter\" , String , callback ) # spin() simply keeps python from exiting until this node is stopped rospy . spin () if __name__ == '__main__' : listener () Modify CMakeLists.txt : catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Build the workspace: cd ~/catkin_ws catkin build Start ROS master and run the 2 nodes. In separate terminal windows: roscore rosrun ros_course talker.py rosrun ros_course listener.py Check the nodes and topic of the system: rosrun rqt_graph rqt_graph Warning! At the end of the lesson, everybody must upload their sources to Moodle as a zip archive! Links ROS Tutorials Curiosity rover simulation","title":"2. Linuxa and ROS principles"},{"location":"02_linux_ros_principles/#02-linux-and-ros-principles","text":"","title":"02. Linux and ROS principles"},{"location":"02_linux_ros_principles/#lecture","text":"","title":"Lecture"},{"location":"02_linux_ros_principles/#linux-principles","text":"Only OS supported by ROS Security Efficieny Open-source Community support User freedom Distributions: Ubuntu , Linux Mint, Debian, etc. Terminal usage more dominant Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator","title":"Linux principles"},{"location":"02_linux_ros_principles/#linux-commands","text":"See some basic commands below: Run as administrator with sudo Manual of command man , e.g. man cp Package management apt , e.g. apt update , apt install Navigation cd List directory contents ls Copy file cp Move file mv Remove file rm Make directory mkdir Remove directory rmdir Make a file executable chmod +x <filename> Safe restart: Crtl + Alt + PrtScr + REISUB If not sure, just google the command","title":"Linux commands"},{"location":"02_linux_ros_principles/#ros-principles","text":"","title":"ROS principles"},{"location":"02_linux_ros_principles/#ros-file-system","text":"ROS package principle Enough functionality to be useful, but not too much that the package is heavyweight and difficult to use from other software.","title":"ROS file system"},{"location":"02_linux_ros_principles/#ros-package","text":"Main unit to organize software in ROS Buildable and redistributable unit of ROS code Consosts of: Manifest (package.xml): information about package name version description dependencies etc. CMakeLists.txt: input for the CMake build system Anything else rosrun turtlesim turtlesim_node","title":"ROS package"},{"location":"02_linux_ros_principles/#ros-node","text":"Executable part of ROS: python scripts compiled C++ code A process that performs computation Inter-node communication: ROS topics (streams) ROS parameter server Remote Procedure Calls (RPC) ROS services ROS actions Meant to operate at a fine-grained scale Typically, a robot control system consists of many nodes, like: Trajectory planning Localization Read sensory data Process sensory data Motor control User interface etc.","title":"ROS node"},{"location":"02_linux_ros_principles/#ros-build-system-catkin","text":"System for building software packages in ROS","title":"ROS build system---Catkin"},{"location":"02_linux_ros_principles/#ros-workspace","text":"Catkin workspace A folder where catkin packages are modified, built, and installed. Source space: Source code of catkin packages Space where you can extract/checkout/clone source code for the packages you want to build Build space CMake is invoked here to build the catkin packages CMake and catkin keep intermediate files here Devel space: Built target are placed here prior to being installed","title":"ROS workspace"},{"location":"02_linux_ros_principles/#environmental-setup-file","text":"setup.bash generated during init process of a new workspace extends shell environment ROS can find any resources that have been installed or built to that location source ~/catkin_ws/devel/setup.bash","title":"Environmental setup file"},{"location":"02_linux_ros_principles/#ros-master","text":"roscore Registers: Nodes Topics Services Parameters One per system roslaunch launches ROS master automatically","title":"ROS master"},{"location":"02_linux_ros_principles/#gyakorlat","text":"Warning! At the end of the lesson, everybody must upload their sources to Moodle as a zip archive!","title":"Gyakorlat"},{"location":"02_linux_ros_principles/#1-turtlesim","text":"Launch ROS master, turtlesim_node and turtle_teleop_key node by typing the following commands to separate terminal windows: Tip In Terminator , Ctrl-Shift-O , Ctrl-Shift-E divides the terimal window, Ctrl-Shift-W closes the current window. roscore rosrun turtlesim turtlesim_node rosrun turtlesim turtle_teleop_key To stup running Ctrl-C Display the running nodes and topics using this command, in a separate terminal: rosrun rqt_graph rqt_graph Try the following commands to gain more information about the currently running system: roswtf rospack list rospack find turtlesim rosnode list rosnode info rosnode info /turtlesim rostopic list rostopic info /turtle1/cmd_vel rosmsg show geometry_msgs/Twist rostopic echo /turtle1/cmd_vel Type (or copy) the following command to the terminal: rostopic pub /turtle1/cmd_vel geometry_msgs/Twist -r 1 -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]'","title":"1: Turtlesim"},{"location":"02_linux_ros_principles/#2-catkin-workspace","text":"Install the catkin build tools package: sudo apt update sudo apt-get install python3-catkin-tools python3-osrf-pycommon Copy the follwoing file to the end of file ~/.bashrc : source /opt/ros/noetic/setup.bash # replace noetic by whatever your ROS distribution is Create the workspace: source /opt/ros/noetic/setup.bash mkdir -p ~/catkin_ws/src cd ~/catkin_ws catkin init","title":"2: Catkin workspace"},{"location":"02_linux_ros_principles/#3-create-a-new-ros-package","text":"Create a new ROS package named ros_course , depends packages std_msgs , rospy and roscpp : cd ~/catkin_ws/src catkin create pkg ros_course --catkin-deps std_msgs rospy roscpp Syntax catkin create pkg <PKG_NAME> --catkin-deps <DEP_1> <DEP_2> Open the file package.xml and fill the following tags: <description> The beginner_tutorials package </description> <maintainer email= \"you@yourdomain.tld\" > Your Name </maintainer> Build the workspace: cd ~/catkin_ws catkin build Danger The commands catkin build and catkin_make are not meant to be used within the same workspace! Append the following line to the file ~/.bashrc : source ~/catkin_ws/devel/setup.bash","title":"3: Create a new ROS package"},{"location":"02_linux_ros_principles/#4-implement-a-publisher-in-python","text":"Create folder named scripts in the ros_course package: cd ~/catkin_ws/src/ros_course mkdir scripts cd scripts Navigate to the scripts folder and create the file talker.py , fill it with the following content: import rospy from std_msgs.msg import String def talker (): rospy . init_node ( 'talker' , anonymous = True ) pub = rospy . Publisher ( 'chatter' , String , queue_size = 10 ) rate = rospy . Rate ( 10 ) # 10hz while not rospy . is_shutdown (): hello_str = \"hello world %s \" % rospy . get_time () print ( hello_str ) pub . publish ( hello_str ) rate . sleep () if __name__ == '__main__' : try : talker () except rospy . ROSInterruptException : pass Open CMakeLists.txt and find the commented out line starting with catkin_install_python (it is near line 167). Uncomment and edit as the following: catkin_install_python ( PROGRAMS scripts/talker.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Build the node: cd ~/catkin_ws catkin build Start ROS master and run the node. In separate terminal windows: roscore rosrun ros_course talker.py Check the output of the node, in a separate terminal: rostopic echo chatter","title":"4: Implement a Publisher in Python"},{"location":"02_linux_ros_principles/#5-implement-a-subscriber-in-python","text":"Navigate to the scripts folder and create the file listener.py : import rospy from std_msgs.msg import String def callback ( data ): print ( rospy . get_caller_id () + \"I heard \" + data . data ) def listener (): # In ROS, nodes are uniquely named. If two nodes with the same # name are launched, the previous one is kicked off. The # anonymous=True flag means that rospy will choose a unique # name for our 'listener' node so that multiple listeners can # run simultaneously. rospy . init_node ( 'listener' , anonymous = True ) rospy . Subscriber ( \"chatter\" , String , callback ) # spin() simply keeps python from exiting until this node is stopped rospy . spin () if __name__ == '__main__' : listener () Modify CMakeLists.txt : catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Build the workspace: cd ~/catkin_ws catkin build Start ROS master and run the 2 nodes. In separate terminal windows: roscore rosrun ros_course talker.py rosrun ros_course listener.py Check the nodes and topic of the system: rosrun rqt_graph rqt_graph Warning! At the end of the lesson, everybody must upload their sources to Moodle as a zip archive!","title":"5: Implement a Subscriber in Python"},{"location":"02_linux_ros_principles/#links","text":"ROS Tutorials Curiosity rover simulation","title":"Links"},{"location":"03_python_principles/","text":"03. Python principles, ROS Publisher, ROS Subscriber Lecture Python principles Interpreted, high-level programming language Name tribute to the comedy group Monty Python Powerful, still easy to learn, easy to use Readability Whitespace indentation Dynamically-typed Garbage colector and reference counting Object oriented programming Used in: AI, web applications, scientific computing, and many other areas python3 Python syntax import numpy as np import math class A : def __init__ ( self , name ): self . name = name def do_something ( self ): # will do something print ( self . name + \" is doing something.\" ) def count_to ( self , n ): # count to n, tell if the number is odd or even for i in range ( n ): if i % 2 == 0 : print ( i + \", it's even.\" ) else : print ( i + \", it's odd.\" ) if __name__ == \"__main__\" : a = A ( \"John\" ) a . do_something () a . count_to ( 10 ) Practice 1: Hello, World! Navigate to the ~/catkin_ws/src/ros_course/scripts/ folder and create the file hello.py : cd catkin_ws/src/ros_course/scripts touch hello.py Type or copy this line into the file hello.py : print ( \"Hello, World!\" ) Tip In gedit: Fix whitespace handling in gedit: Preferences -> Editor -> Insert spaces instead of tabs. To run the file, cd to the scripts directory and type: python3 hello.py Tip In the case of issues with permissions, type the following to grant the file permission to execute: chmod +x hello.py Modify the script to replace the word \"World\" with a command line argument: import sys msg = sys . argv [ 1 ] print ( \"Hello,\" , msg , \"!\" ) Run the file: python3 hello.py John 2: Moving the turtle straight Write a ROS node which communicates with the turtlesim_node and moves the turtle straight forward until it reaches the given distance. Open a terminal and create the file turtlesim_controller.py in the folder `~/catkin_ws/src/ros_course/scripts: cd catkin_ws/src/ros_course/scripts touch turtlesim_controller.py Add turtlesim_controller.py to CMakeLists.txt : catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py scripts/turtlesim_controller.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Copy the skeleton of the program into turtlesim_controller.py : import rospy import math class TurtlesimController : def __init__ ( self ): # Call init node only once rospy . init_node ( 'turtlesim_controller' , anonymous = True ) # Define publisher here def go_straight ( self , speed , distance , forward ): # Implement straght motion here if __name__ == '__main__' : # Init tc = TurtlesimController () # Send turtle on a straight line tc . go_straight ( 1 , 4 , True ) Launch a turtlesim_node , then find the topic we can use to control its movement. In three separate terminal windows: roscore rosrun turtlesim turtlesim_node rostopic list rostopic info /turtle1/cmd_vel rosmsg show geometry_msgs/Twist Import the message type geometry_msgs/Twist and create the publisher handle object for the topic named turtlesim_controller.py : from geometry_msgs.msg import Twist #... self . twist_pub = rospy . Publisher ( '/turtle1/cmd_vel' , Twist , queue_size = 10 ) Implement the go_straight method. Calculate how much time it takes for the turtle to move to the given distance with the given velocity. Publish and repeat a message to set the velocity, and when the calculated time is up, send another message to set the velocity to 0. A little help on the usage of the API: # Create and publish msg vel_msg = Twist () if forward : vel_msg . linear . x = speed else : vel_msg . linear . x = - speed vel_msg . linear . y = 0 vel_msg . linear . z = 0 vel_msg . angular . x = 0 vel_msg . angular . y = 0 vel_msg . angular . z = 0 # Set loop rate rate = rospy . Rate ( 100 ) # Hz # Publish first msg and note time self . twist_pub . publish ( vel_msg ) t0 = rospy . Time . now () . to_sec () # Publish msg while the calculated time is up while ( some condition ... ) and not ( rospy . is_shutdown ()): self . twist_pub . publish ( vel_msg ) # ...and stuff rate . sleep () # loop rate # Set velocity to 0 vel_msg . linear . x = 0 self . twist_pub . publish ( vel_msg ) Launch the node: rosrun ros_course turtlesim_controller.py 3: Drawing polygons Implement a method to turn the turtle with a given angle in turtlesim_controller.py in a similar way to the straight movement. Omega refers to the angular velocity. def turn ( self , omega , angle , forward ): # Implement rotation here Implement a method that draws a square with the turtle. Use the methods go_straight and turn . def draw_square ( self , speed , omega , a ): Implement a method to draw arbitrary regular polygons. def draw_poly ( self , speed , omega , N , a ): 4: Go to method Search for the topic turtlesim which publsihes the pose (position and orientation) of the turtle into: rostopic list rostopic info /turtle1/pose rosmsg show turtlesim/Pose Create a subscriber for the topic and write the callback function: # Imports from turtlesim.msg import Pose # Constructor self . pose_subscriber = rospy . Subscriber ( '/turtle1/pose' , Pose , self . cb_pose ) # New method for TurtlesimController def cb_pose ( self , msg ): self . pose = msg Implement the method go_to . Test it by calling from the main. # ... # Go to method def go_to ( self , speed , omega , x , y ): # Stuff # Main if __name__ == '__main__' : # Init tc = TurtlesimController () # 1 sec sleep so subscriber can get msgs rospy . sleep ( 1 ) tc . go_to ( 1 , 2 , 2 , 8 ) tc . go_to ( 1 , 2 , 2 , 2 ) tc . go_to ( 1 , 2 , 3 , 4 ) tc . go_to ( 1 , 2 , 6 , 2 ) Bonus exercise: Advanced go to Write a more accurate go to method using proportional controller. Useful links For loops in python Some python functions Turtlesim documentation atan2","title":"3. Python principles, ROS Publisher, ROS Subscriber"},{"location":"03_python_principles/#03-python-principles-ros-publisher-ros-subscriber","text":"","title":"03. Python principles, ROS Publisher, ROS Subscriber"},{"location":"03_python_principles/#lecture","text":"","title":"Lecture"},{"location":"03_python_principles/#python-principles","text":"Interpreted, high-level programming language Name tribute to the comedy group Monty Python Powerful, still easy to learn, easy to use Readability Whitespace indentation Dynamically-typed Garbage colector and reference counting Object oriented programming Used in: AI, web applications, scientific computing, and many other areas python3","title":"Python principles"},{"location":"03_python_principles/#python-syntax","text":"import numpy as np import math class A : def __init__ ( self , name ): self . name = name def do_something ( self ): # will do something print ( self . name + \" is doing something.\" ) def count_to ( self , n ): # count to n, tell if the number is odd or even for i in range ( n ): if i % 2 == 0 : print ( i + \", it's even.\" ) else : print ( i + \", it's odd.\" ) if __name__ == \"__main__\" : a = A ( \"John\" ) a . do_something () a . count_to ( 10 )","title":"Python syntax"},{"location":"03_python_principles/#practice","text":"","title":"Practice"},{"location":"03_python_principles/#1-hello-world","text":"Navigate to the ~/catkin_ws/src/ros_course/scripts/ folder and create the file hello.py : cd catkin_ws/src/ros_course/scripts touch hello.py Type or copy this line into the file hello.py : print ( \"Hello, World!\" ) Tip In gedit: Fix whitespace handling in gedit: Preferences -> Editor -> Insert spaces instead of tabs. To run the file, cd to the scripts directory and type: python3 hello.py Tip In the case of issues with permissions, type the following to grant the file permission to execute: chmod +x hello.py Modify the script to replace the word \"World\" with a command line argument: import sys msg = sys . argv [ 1 ] print ( \"Hello,\" , msg , \"!\" ) Run the file: python3 hello.py John","title":"1: Hello, World!"},{"location":"03_python_principles/#2-moving-the-turtle-straight","text":"Write a ROS node which communicates with the turtlesim_node and moves the turtle straight forward until it reaches the given distance. Open a terminal and create the file turtlesim_controller.py in the folder `~/catkin_ws/src/ros_course/scripts: cd catkin_ws/src/ros_course/scripts touch turtlesim_controller.py Add turtlesim_controller.py to CMakeLists.txt : catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py scripts/turtlesim_controller.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Copy the skeleton of the program into turtlesim_controller.py : import rospy import math class TurtlesimController : def __init__ ( self ): # Call init node only once rospy . init_node ( 'turtlesim_controller' , anonymous = True ) # Define publisher here def go_straight ( self , speed , distance , forward ): # Implement straght motion here if __name__ == '__main__' : # Init tc = TurtlesimController () # Send turtle on a straight line tc . go_straight ( 1 , 4 , True ) Launch a turtlesim_node , then find the topic we can use to control its movement. In three separate terminal windows: roscore rosrun turtlesim turtlesim_node rostopic list rostopic info /turtle1/cmd_vel rosmsg show geometry_msgs/Twist Import the message type geometry_msgs/Twist and create the publisher handle object for the topic named turtlesim_controller.py : from geometry_msgs.msg import Twist #... self . twist_pub = rospy . Publisher ( '/turtle1/cmd_vel' , Twist , queue_size = 10 ) Implement the go_straight method. Calculate how much time it takes for the turtle to move to the given distance with the given velocity. Publish and repeat a message to set the velocity, and when the calculated time is up, send another message to set the velocity to 0. A little help on the usage of the API: # Create and publish msg vel_msg = Twist () if forward : vel_msg . linear . x = speed else : vel_msg . linear . x = - speed vel_msg . linear . y = 0 vel_msg . linear . z = 0 vel_msg . angular . x = 0 vel_msg . angular . y = 0 vel_msg . angular . z = 0 # Set loop rate rate = rospy . Rate ( 100 ) # Hz # Publish first msg and note time self . twist_pub . publish ( vel_msg ) t0 = rospy . Time . now () . to_sec () # Publish msg while the calculated time is up while ( some condition ... ) and not ( rospy . is_shutdown ()): self . twist_pub . publish ( vel_msg ) # ...and stuff rate . sleep () # loop rate # Set velocity to 0 vel_msg . linear . x = 0 self . twist_pub . publish ( vel_msg ) Launch the node: rosrun ros_course turtlesim_controller.py","title":"2: Moving the turtle straight"},{"location":"03_python_principles/#3-drawing-polygons","text":"Implement a method to turn the turtle with a given angle in turtlesim_controller.py in a similar way to the straight movement. Omega refers to the angular velocity. def turn ( self , omega , angle , forward ): # Implement rotation here Implement a method that draws a square with the turtle. Use the methods go_straight and turn . def draw_square ( self , speed , omega , a ): Implement a method to draw arbitrary regular polygons. def draw_poly ( self , speed , omega , N , a ):","title":"3: Drawing polygons"},{"location":"03_python_principles/#4-go-to-method","text":"Search for the topic turtlesim which publsihes the pose (position and orientation) of the turtle into: rostopic list rostopic info /turtle1/pose rosmsg show turtlesim/Pose Create a subscriber for the topic and write the callback function: # Imports from turtlesim.msg import Pose # Constructor self . pose_subscriber = rospy . Subscriber ( '/turtle1/pose' , Pose , self . cb_pose ) # New method for TurtlesimController def cb_pose ( self , msg ): self . pose = msg Implement the method go_to . Test it by calling from the main. # ... # Go to method def go_to ( self , speed , omega , x , y ): # Stuff # Main if __name__ == '__main__' : # Init tc = TurtlesimController () # 1 sec sleep so subscriber can get msgs rospy . sleep ( 1 ) tc . go_to ( 1 , 2 , 2 , 8 ) tc . go_to ( 1 , 2 , 2 , 2 ) tc . go_to ( 1 , 2 , 3 , 4 ) tc . go_to ( 1 , 2 , 6 , 2 )","title":"4: Go to method"},{"location":"03_python_principles/#bonus-exercise-advanced-go-to","text":"Write a more accurate go to method using proportional controller.","title":"Bonus exercise: Advanced go to"},{"location":"03_python_principles/#useful-links","text":"For loops in python Some python functions Turtlesim documentation atan2","title":"Useful links"},{"location":"04_git/","text":"04. Versioning, Git Lecture Version control, Git Track changes in a set of files Coordinating work among developers Who made what changes and when Revert back at any time Local and remote repos Take snapshots of files by making a commit Install sudo apt install git Basic commands git init # Initialize local git repo git add <file> # Add file/files to staging area git status # Check status of working tree and staging area git commit -m \"What I've done\" # Commit changes in index git push # Push to remote repository git pull # Pull latest changes from remote repo git branch <new_branch_name> git checkout <branch_name> git merge <branch_name> # Merge the branch into the current branch git config --global user.name \"Istvan Szabo\" git config --global user.email \"istvan.szabo@gmail.com\" Tip Store personal token: git config --global credential.helper store Tip Windows and Linux clock issue: timedatectl set-local-rtc 1 --adjust-system-clock GitHub git remote git clone <link> # Copy repo into a new directory # Add remote to repository: git remote add origin <link> git push -u origin master Some alternatives to GitHub GitLab, BitBucket, Launchpad, Phabricator Markdown Markup language, easy to read Text file \u2192 Formatted document Widespread usag, e.g., blogs, forums, documentations, readme files, GitHub Markdown Cheatsheet Gyakorlat 0: GitHub repo l\u00e9trehoz\u00e1sa Inicializ\u00e1ljunk egy lok\u00e1lis git repo-t a ros-course package-ben. Regisztr\u00e1ljunk GitHub-ra, majd hozzunk l\u00e9tre egy private repo-t a ros_course package sz\u00e1m\u00e1ra. \u00c1ll\u00edtsuk be a local repo-ban a remote-ot, majd push-oljuk a package tartalm\u00e1t.","title":"4. Versioning, Git"},{"location":"04_git/#04-versioning-git","text":"","title":"04. Versioning, Git"},{"location":"04_git/#lecture","text":"","title":"Lecture"},{"location":"04_git/#version-control-git","text":"Track changes in a set of files Coordinating work among developers Who made what changes and when Revert back at any time Local and remote repos Take snapshots of files by making a commit","title":"Version control, Git"},{"location":"04_git/#install","text":"sudo apt install git","title":"Install"},{"location":"04_git/#basic-commands","text":"git init # Initialize local git repo git add <file> # Add file/files to staging area git status # Check status of working tree and staging area git commit -m \"What I've done\" # Commit changes in index git push # Push to remote repository git pull # Pull latest changes from remote repo git branch <new_branch_name> git checkout <branch_name> git merge <branch_name> # Merge the branch into the current branch git config --global user.name \"Istvan Szabo\" git config --global user.email \"istvan.szabo@gmail.com\" Tip Store personal token: git config --global credential.helper store Tip Windows and Linux clock issue: timedatectl set-local-rtc 1 --adjust-system-clock","title":"Basic commands"},{"location":"04_git/#github","text":"git remote git clone <link> # Copy repo into a new directory # Add remote to repository: git remote add origin <link> git push -u origin master Some alternatives to GitHub GitLab, BitBucket, Launchpad, Phabricator","title":"GitHub"},{"location":"04_git/#markdown","text":"Markup language, easy to read Text file \u2192 Formatted document Widespread usag, e.g., blogs, forums, documentations, readme files, GitHub Markdown Cheatsheet","title":"Markdown"},{"location":"04_git/#gyakorlat","text":"","title":"Gyakorlat"},{"location":"04_git/#0-github-repo-letrehozasa","text":"Inicializ\u00e1ljunk egy lok\u00e1lis git repo-t a ros-course package-ben. Regisztr\u00e1ljunk GitHub-ra, majd hozzunk l\u00e9tre egy private repo-t a ros_course package sz\u00e1m\u00e1ra. \u00c1ll\u00edtsuk be a local repo-ban a remote-ot, majd push-oljuk a package tartalm\u00e1t.","title":"0: GitHub repo l\u00e9trehoz\u00e1sa"},{"location":"05_da_vinci/","text":"05. Principles of robotics. Programming a da Vinci surgical robot in simulated environment. Lecture Warning Test 1 (ROS principles, publisher, subscriber. Python principles. Principles of robotics.) October 11. Rigid body motion Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis. 3D transformations Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters. Principles of robotics Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques.... Python libraries Numpy Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy Matplotlib Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib Practice 1. DVRK install The da Vinci Surgical System is used to perform minimally invasive surgeries by teleoperation. The da Vinci Research Kit (DVRK) is an open-source hardware and software platform, offers, amongst others, reading and writing all the joints of the da Vinci, and also simulators for each arm. The DVRK software can be built as follows. On Ubuntu 20.04 the following packages are required: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-wstool python3-catkin-tools python3-osrf-pycommon ros-noetic-rviz Download and install DVRK packages: cd ~/catkin_ws # go in the workspace wstool init src # we're going to use wstool to pull all the code from github catkin config --cmake-args -DCMAKE_BUILD_TYPE = Release # all code should be compiled in release mode cd src # go in source directory to pull code wstool merge https://raw.githubusercontent.com/jhu-dvrk/dvrk-ros/master/dvrk_ros.rosinstall # or replace master by devel wstool up # now wstool knows which repositories to pull, let's get the code cd ~/catkin_ws catkin build --summary # ... and finally compile everything Restart the terminal then launch the RViz simulation of the PSM1 (Patient Side Manipulator): roslaunch dvrk_robot dvrk_arm_rviz.launch arm: = PSM1 config: = /home/ $( whoami ) /catkin_ws/src/cisst-saw/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json !!! tip `Roslaunch` also launches the ROS master, if there is no ROS master running. --- 2. PSM subscriber Create a new file named psm_grasp.py in the ~/catkin_ws/src/ros_course/scripts folder. Add it to the CMakeLists.txt , as usually. Check the topics and nodes of the simulator using the commands learned earlier ( rostopic list , rosrun rqt_graph rqt_graph , etc.). PSM1 publishes the pose of the TCP and the angle of the jaws into the topics below. Subscribe to these topic in psm_grasp.py and store the current values into variables. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: cd ~/catkin_ws catkin build ros_course rosrun ros_course psm_grasp.py 3. Move the TCP along a linear trajectory PSM1 expects commands regarding the pose of the TCP and the angle of the jaws from the topics below. Create publishers to these topic in psm_grasp.py . /PSM1/servo_cp /PSM1/jaw/servo_jp Implement a method that moves the TCP to the desired position along a linear trajectory. Send the gripper to the position (0.0, 0.05, -0.12), leave the orientation as it is. Let the sampling time dt be 0.01s. def move_tcp_to ( self , target , v , dt ): Tip Use the function np.linspace(start, stop, num) to create the array of t values (T). This function can also be used to create the linear trajectory along the axes x, y, z in separate arrays X, Y and Z. Write a method that can open and close the gripper jaws, also along a linear trajectory. def move_jaw_to ( self , target , omega , dt ): 4. Dummy marker Write a node that creates a virtual marker that can be grasped publishing visualization_msgs/Marker messages. Create a new file named dummy_marker.py in the ~/catkin_ws/src/ros_course/scripts folder. Add it to the CMakeLists.txt , as usually. Copy the following code into the file dummy_marker.py : import rospy from visualization_msgs.msg import Marker def marker ( position ): rospy . init_node ( 'dummy_target_publisher' , anonymous = True ) pub = rospy . Publisher ( 'dummy_target_marker' , Marker , queue_size = 10 ) rate = rospy . Rate ( 10 ) # 10hz i = 0 while not rospy . is_shutdown (): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = rospy . Time () marker . ns = \"dvrk_viz\" marker . id = i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = position [ 0 ] marker . pose . position . y = position [ 1 ] marker . pose . position . z = position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; #rospy.loginfo(marker) pub . publish ( marker ) i = i + 1 rate . sleep () if __name__ == '__main__' : try : marker ([ - 0.05 , 0.08 , - 0.12 ]) except rospy . ROSInterruptException : pass Build and run the node. Visualize the marker in RViz. 5. Grasp the marker Subscribe to the topic with the marker position dummy_target_publisher the file psm_grasp.py . Implement a method in psm_grasp.py to grasp the generated marker with PSM1. Note Some values tends to stuck in the simulator. Thus, at the beginning of the program, it is a good idea to reset the arm: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 ) Links Download and compile dVRK Marker examples Numpy vector magnitude Numpy linspace","title":"5. Principles of robotics, da Vinci"},{"location":"05_da_vinci/#05-principles-of-robotics-programming-a-da-vinci-surgical-robot-in-simulated-environment","text":"","title":"05. Principles of robotics. Programming a da Vinci surgical robot in simulated environment."},{"location":"05_da_vinci/#lecture","text":"Warning Test 1 (ROS principles, publisher, subscriber. Python principles. Principles of robotics.) October 11.","title":"Lecture"},{"location":"05_da_vinci/#rigid-body-motion","text":"Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis.","title":"Rigid body motion"},{"location":"05_da_vinci/#3d-transformations","text":"Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters.","title":"3D transformations"},{"location":"05_da_vinci/#principles-of-robotics","text":"Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques....","title":"Principles of robotics"},{"location":"05_da_vinci/#python-libraries","text":"","title":"Python libraries"},{"location":"05_da_vinci/#numpy","text":"Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy","title":"Numpy"},{"location":"05_da_vinci/#matplotlib","text":"Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib","title":"Matplotlib"},{"location":"05_da_vinci/#practice","text":"","title":"Practice"},{"location":"05_da_vinci/#1-dvrk-install","text":"The da Vinci Surgical System is used to perform minimally invasive surgeries by teleoperation. The da Vinci Research Kit (DVRK) is an open-source hardware and software platform, offers, amongst others, reading and writing all the joints of the da Vinci, and also simulators for each arm. The DVRK software can be built as follows. On Ubuntu 20.04 the following packages are required: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-wstool python3-catkin-tools python3-osrf-pycommon ros-noetic-rviz Download and install DVRK packages: cd ~/catkin_ws # go in the workspace wstool init src # we're going to use wstool to pull all the code from github catkin config --cmake-args -DCMAKE_BUILD_TYPE = Release # all code should be compiled in release mode cd src # go in source directory to pull code wstool merge https://raw.githubusercontent.com/jhu-dvrk/dvrk-ros/master/dvrk_ros.rosinstall # or replace master by devel wstool up # now wstool knows which repositories to pull, let's get the code cd ~/catkin_ws catkin build --summary # ... and finally compile everything Restart the terminal then launch the RViz simulation of the PSM1 (Patient Side Manipulator): roslaunch dvrk_robot dvrk_arm_rviz.launch arm: = PSM1 config: = /home/ $( whoami ) /catkin_ws/src/cisst-saw/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json !!! tip `Roslaunch` also launches the ROS master, if there is no ROS master running. ---","title":"1. DVRK install"},{"location":"05_da_vinci/#2-psm-subscriber","text":"Create a new file named psm_grasp.py in the ~/catkin_ws/src/ros_course/scripts folder. Add it to the CMakeLists.txt , as usually. Check the topics and nodes of the simulator using the commands learned earlier ( rostopic list , rosrun rqt_graph rqt_graph , etc.). PSM1 publishes the pose of the TCP and the angle of the jaws into the topics below. Subscribe to these topic in psm_grasp.py and store the current values into variables. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: cd ~/catkin_ws catkin build ros_course rosrun ros_course psm_grasp.py","title":"2. PSM subscriber"},{"location":"05_da_vinci/#3-move-the-tcp-along-a-linear-trajectory","text":"PSM1 expects commands regarding the pose of the TCP and the angle of the jaws from the topics below. Create publishers to these topic in psm_grasp.py . /PSM1/servo_cp /PSM1/jaw/servo_jp Implement a method that moves the TCP to the desired position along a linear trajectory. Send the gripper to the position (0.0, 0.05, -0.12), leave the orientation as it is. Let the sampling time dt be 0.01s. def move_tcp_to ( self , target , v , dt ): Tip Use the function np.linspace(start, stop, num) to create the array of t values (T). This function can also be used to create the linear trajectory along the axes x, y, z in separate arrays X, Y and Z. Write a method that can open and close the gripper jaws, also along a linear trajectory. def move_jaw_to ( self , target , omega , dt ):","title":"3. Move the TCP along a linear trajectory"},{"location":"05_da_vinci/#4-dummy-marker","text":"Write a node that creates a virtual marker that can be grasped publishing visualization_msgs/Marker messages. Create a new file named dummy_marker.py in the ~/catkin_ws/src/ros_course/scripts folder. Add it to the CMakeLists.txt , as usually. Copy the following code into the file dummy_marker.py : import rospy from visualization_msgs.msg import Marker def marker ( position ): rospy . init_node ( 'dummy_target_publisher' , anonymous = True ) pub = rospy . Publisher ( 'dummy_target_marker' , Marker , queue_size = 10 ) rate = rospy . Rate ( 10 ) # 10hz i = 0 while not rospy . is_shutdown (): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = rospy . Time () marker . ns = \"dvrk_viz\" marker . id = i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = position [ 0 ] marker . pose . position . y = position [ 1 ] marker . pose . position . z = position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; #rospy.loginfo(marker) pub . publish ( marker ) i = i + 1 rate . sleep () if __name__ == '__main__' : try : marker ([ - 0.05 , 0.08 , - 0.12 ]) except rospy . ROSInterruptException : pass Build and run the node. Visualize the marker in RViz.","title":"4. Dummy marker"},{"location":"05_da_vinci/#5-grasp-the-marker","text":"Subscribe to the topic with the marker position dummy_target_publisher the file psm_grasp.py . Implement a method in psm_grasp.py to grasp the generated marker with PSM1. Note Some values tends to stuck in the simulator. Thus, at the beginning of the program, it is a good idea to reset the arm: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 )","title":"5. Grasp the marker"},{"location":"05_da_vinci/#links","text":"Download and compile dVRK Marker examples Numpy vector magnitude Numpy linspace","title":"Links"},{"location":"06_roslaunch/","text":"08. Roslaunch, ROS parameter szerver, Rosbag Lecture Roslaunch Launch multiple nodes Also launches ROS master if not running Set parameters XML file format, .launch extension Example launch file <!-- dvrk_server.launch --> <!-- Launch the irob dVRK high-level robot controller. After start, it will wait for irob_msgs/Robot actions --> <launch> <group ns= \"saf\" > <arg name= \"arm_typ\" default= \"PSM2\" /> <arg name= \"arm_name\" default= \"arm_1\" /> <arg name= \"camera_registration_file\" default= \"registration_psm1.yaml\" /> <arg name= \"instrument_info_file\" default= \"prograsp_forceps.yaml\" /> <include file= \"$(find irob_robot)/config/dvrk_topic_names.xml\" /> <node name= \"robot_server_$(arg arm_typ)\" pkg= \"irob_robot\" type= \"robot_server_dvrk\" output= \"screen\" > <param name= \"arm_typ\" type= \"string\" value= \"$(arg arm_typ)\" /> <param name= \"arm_name\" type= \"string\" value= \"$(arg arm_name)\" /> <param name= \"home_joint_angles\" type= \"yaml\" value= \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\" /> <rosparam command= \"load\" file= \"$(find irob_robot)/config/$(arg camera_registration_file)\" /> <rosparam command= \"load\" file= \"$(find irob_robot)/config/$(arg instrument_info_file)\" /> </node> </group> </launch> Usage roslaunch package_name file.launch roslaunch irob_robot dvrk_server.launch arm_typ: = PSM1 ROS Parameter Server Nodes can store and retrieve parameters at runtime Shared dictionary Best use for configuration ROS naming convention Private parameters (~) Available data types: 32-bit integers booleans strings doubles iso8601 dates lists base64-encoded binary data Useful command: rosparam Python API # Call AFTER rospy.init_node() # Getting parameters global_name = rospy . get_param ( \"/global_name\" ) relative_name = rospy . get_param ( \"relative_name\" ) private_param = rospy . get_param ( '~private_name' ) default_param = rospy . get_param ( 'default_param' , 'default_value' ) # fetch a group (dictionary) of parameters gains = rospy . get_param ( 'gains' ) p , i , d = gains [ 'p' ], gains [ 'i' ], gains [ 'd' ] # Setting parameters # Using rospy and raw python objects rospy . set_param ( 'a_string' , 'baz' ) rospy . set_param ( '~private_int' , 2 ) rospy . set_param ( 'list_of_floats' , [ 1. , 2. , 3. , 4. ]) rospy . set_param ( 'bool_True' , True ) rospy . set_param ( 'gains' , { 'p' : 1 , 'i' : 2 , 'd' : 3 }) # Using rosparam and yaml strings rosparam . set_param ( 'a_string' , 'baz' ) rosparam . set_param ( '~private_int' , '2' ) rosparam . set_param ( 'list_of_floats' , \"[1., 2., 3., 4.]\" ) rosparam . set_param ( 'bool_True' , \"true\" ) rosparam . set_param ( 'gains' , \"{'p': 1, 'i': 2, 'd': 3}\" ) rospy . get_param ( 'gains/p' ) #should return 1 Roslaunch API <param name= \"arm_typ\" type= \"string\" value= \"ECM\" /> <param name= \"publish_frequency\" type= \"double\" value= \"10.0\" /> <rosparam command= \"load\" file= \"FILENAME\" /> YAML \u201cA human friendly data serialization standard for all programming languages\u201d # registration_identity.yaml t : [ 0.0 , 0.0 , 0.0 ] R : [ 1.0 , 0.0 , 0.0 , 0.0 , 1.0 , 0.0 , 0.0 , 0.0 , 1.0 ] Rosbag Record and playback ROS topics Command line tool API for C++ and Python rosbag record <topic_name> rosbag record --all rosbag play <filename.bag> Practice 1: Marker: Disk Create a new file named dummy_cylinder.py in the scripts folder. Publish disk shaped Marker with position (0.05, 0.05, -0.15) and radius of 0.1 m. 2: Launchfile and params for the markers Create a new file named dummy_markers.launch in the folder ~catkin_ws/src/ros_course/launch . If the folder does not exist, create that as well. Write a launchfile, that launches both dummy marker publisher nodes. Modify the launchfile and the Python scripts so the dummy marker publishers receive the position of the marker as a ROS parameter, that can also be set from the command line (see the example in Chapter 6). Let the position of the markers have default values too, sphere: (-0.05, 0.1, -0.12), disk: (0.05, 0.05, -0.15). Create a YAML file, containing the size and the color of the disk marker. Load those parameters in the Python script through roslaunch. 3: Navigation around the perimeter Create a new launchfile named psm_grasp.launch for the script psm_grasp.py . Let dt, velocity and angular velocity of the jaws be set as ROS parameters. Run psm_grasp.launch with different marker positions. Modify psm_grasp.py so that the TCP moves around the perimeter of the disk marker before grasping the spherical one. 4: Record with rosbag While running the program implemented in the previous exercise, record the contents of all topics to a bag file. rosbag record --all Install the package rqt . sudo apt-get update sudo apt-get install ros-noetic-rqt sudo apt-get install ros-noetic-rqt-common-plugins Play back the recorded bag file and echo some of the PSM1's topics (or visualize the coordinates of the PSM TCP using rqt_plot ). rosbag play <filename.bag> rostopic echo /PSM1/measured_cp Hasznos linkek Roslaunch ROS Parameter Server Python API for the ROS Parameter Server tag in roslaunch Rosparam YAML Rosbag rqt_plot","title":"6. Roslaunch, msg, action, service"},{"location":"06_roslaunch/#08-roslaunch-ros-parameter-szerver-rosbag","text":"","title":"08. Roslaunch, ROS parameter szerver, Rosbag"},{"location":"06_roslaunch/#lecture","text":"","title":"Lecture"},{"location":"06_roslaunch/#roslaunch","text":"Launch multiple nodes Also launches ROS master if not running Set parameters XML file format, .launch extension","title":"Roslaunch"},{"location":"06_roslaunch/#example-launch-file","text":"<!-- dvrk_server.launch --> <!-- Launch the irob dVRK high-level robot controller. After start, it will wait for irob_msgs/Robot actions --> <launch> <group ns= \"saf\" > <arg name= \"arm_typ\" default= \"PSM2\" /> <arg name= \"arm_name\" default= \"arm_1\" /> <arg name= \"camera_registration_file\" default= \"registration_psm1.yaml\" /> <arg name= \"instrument_info_file\" default= \"prograsp_forceps.yaml\" /> <include file= \"$(find irob_robot)/config/dvrk_topic_names.xml\" /> <node name= \"robot_server_$(arg arm_typ)\" pkg= \"irob_robot\" type= \"robot_server_dvrk\" output= \"screen\" > <param name= \"arm_typ\" type= \"string\" value= \"$(arg arm_typ)\" /> <param name= \"arm_name\" type= \"string\" value= \"$(arg arm_name)\" /> <param name= \"home_joint_angles\" type= \"yaml\" value= \"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\" /> <rosparam command= \"load\" file= \"$(find irob_robot)/config/$(arg camera_registration_file)\" /> <rosparam command= \"load\" file= \"$(find irob_robot)/config/$(arg instrument_info_file)\" /> </node> </group> </launch>","title":"Example launch file"},{"location":"06_roslaunch/#usage","text":"roslaunch package_name file.launch roslaunch irob_robot dvrk_server.launch arm_typ: = PSM1","title":"Usage"},{"location":"06_roslaunch/#ros-parameter-server","text":"Nodes can store and retrieve parameters at runtime Shared dictionary Best use for configuration ROS naming convention Private parameters (~) Available data types: 32-bit integers booleans strings doubles iso8601 dates lists base64-encoded binary data Useful command: rosparam","title":"ROS Parameter Server"},{"location":"06_roslaunch/#python-api","text":"# Call AFTER rospy.init_node() # Getting parameters global_name = rospy . get_param ( \"/global_name\" ) relative_name = rospy . get_param ( \"relative_name\" ) private_param = rospy . get_param ( '~private_name' ) default_param = rospy . get_param ( 'default_param' , 'default_value' ) # fetch a group (dictionary) of parameters gains = rospy . get_param ( 'gains' ) p , i , d = gains [ 'p' ], gains [ 'i' ], gains [ 'd' ] # Setting parameters # Using rospy and raw python objects rospy . set_param ( 'a_string' , 'baz' ) rospy . set_param ( '~private_int' , 2 ) rospy . set_param ( 'list_of_floats' , [ 1. , 2. , 3. , 4. ]) rospy . set_param ( 'bool_True' , True ) rospy . set_param ( 'gains' , { 'p' : 1 , 'i' : 2 , 'd' : 3 }) # Using rosparam and yaml strings rosparam . set_param ( 'a_string' , 'baz' ) rosparam . set_param ( '~private_int' , '2' ) rosparam . set_param ( 'list_of_floats' , \"[1., 2., 3., 4.]\" ) rosparam . set_param ( 'bool_True' , \"true\" ) rosparam . set_param ( 'gains' , \"{'p': 1, 'i': 2, 'd': 3}\" ) rospy . get_param ( 'gains/p' ) #should return 1","title":"Python API"},{"location":"06_roslaunch/#roslaunch-api","text":"<param name= \"arm_typ\" type= \"string\" value= \"ECM\" /> <param name= \"publish_frequency\" type= \"double\" value= \"10.0\" /> <rosparam command= \"load\" file= \"FILENAME\" />","title":"Roslaunch API"},{"location":"06_roslaunch/#yaml","text":"\u201cA human friendly data serialization standard for all programming languages\u201d # registration_identity.yaml t : [ 0.0 , 0.0 , 0.0 ] R : [ 1.0 , 0.0 , 0.0 , 0.0 , 1.0 , 0.0 , 0.0 , 0.0 , 1.0 ]","title":"YAML"},{"location":"06_roslaunch/#rosbag","text":"Record and playback ROS topics Command line tool API for C++ and Python rosbag record <topic_name> rosbag record --all rosbag play <filename.bag>","title":"Rosbag"},{"location":"06_roslaunch/#practice","text":"","title":"Practice"},{"location":"06_roslaunch/#1-marker-disk","text":"Create a new file named dummy_cylinder.py in the scripts folder. Publish disk shaped Marker with position (0.05, 0.05, -0.15) and radius of 0.1 m.","title":"1: Marker: Disk"},{"location":"06_roslaunch/#2-launchfile-and-params-for-the-markers","text":"Create a new file named dummy_markers.launch in the folder ~catkin_ws/src/ros_course/launch . If the folder does not exist, create that as well. Write a launchfile, that launches both dummy marker publisher nodes. Modify the launchfile and the Python scripts so the dummy marker publishers receive the position of the marker as a ROS parameter, that can also be set from the command line (see the example in Chapter 6). Let the position of the markers have default values too, sphere: (-0.05, 0.1, -0.12), disk: (0.05, 0.05, -0.15). Create a YAML file, containing the size and the color of the disk marker. Load those parameters in the Python script through roslaunch.","title":"2: Launchfile and params for the markers"},{"location":"06_roslaunch/#3-navigation-around-the-perimeter","text":"Create a new launchfile named psm_grasp.launch for the script psm_grasp.py . Let dt, velocity and angular velocity of the jaws be set as ROS parameters. Run psm_grasp.launch with different marker positions. Modify psm_grasp.py so that the TCP moves around the perimeter of the disk marker before grasping the spherical one.","title":"3: Navigation around the perimeter"},{"location":"06_roslaunch/#4-record-with-rosbag","text":"While running the program implemented in the previous exercise, record the contents of all topics to a bag file. rosbag record --all Install the package rqt . sudo apt-get update sudo apt-get install ros-noetic-rqt sudo apt-get install ros-noetic-rqt-common-plugins Play back the recorded bag file and echo some of the PSM1's topics (or visualize the coordinates of the PSM TCP using rqt_plot ). rosbag play <filename.bag> rostopic echo /PSM1/measured_cp","title":"4: Record with rosbag"},{"location":"06_roslaunch/#hasznos-linkek","text":"Roslaunch ROS Parameter Server Python API for the ROS Parameter Server tag in roslaunch Rosparam YAML Rosbag rqt_plot","title":"Hasznos linkek"},{"location":"07_robotics_principles/","text":"07. Kinematics, inverse kinematics. Programming a simulated robot in joint space and task space Warning ZH2 (Roslaunch, ROS parameter szerver. ROS service. ROS action. Kinematics, inverse kinematics) and project presentation : December 6. Rehearsal 3D transformations Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters. Principles of robotics Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques.... Lecture Kinematics, inverse kinematics Def. Kinematics Calculation of the pose of the TCP from joint angles. (From joint space to task space) Kinematic model Denavit--Hartenberg (HD) convention URDF (Unified Robotics Description Format, XML-based) If the frames attached to each segment are named \\(base, 1, 2, 3, ..., TCP\\) , transformations between two neighboring segments \\(i\\) and \\(i+1\\) ---dependent on the angle of the joint enclosed by them---are named \\(T_{i+1,i}(q_{i+1})\\) , the transformation from the base frame to the TCP can be calculated as follows for a robot with \\(n\\) joints: \\[ T_{TCP,base}(q_1, \\cdots, q_n) = T_{TCP,n-1}(q_{n}) \\cdot T_{n-1,n-2}(q_{n-1}) \\cdots T_{2,1}(q_2) \\cdot T_{1,base}(q_1) \\cdot base \\] Def. Inverse kinematics Calculation of the joint angles in order to reach desired (or any) TCP pose. (From task space to joint space) Differential inverse kinematics Def. Differential inverse kinematics How to change the joint angles to achieve the desired small change in TCP pose (including rotation and translation). Jacobian matrix (Jacobian): The Jacobian matrix of a vector-valued function of several variables is the matrix of all its first-order partial derivatives. \\[ \\mathbf{J} = \\left[\\matrix{\\frac{\\partial x_1}{\\partial q_1} & \\frac{\\partial x_1}{\\partial q_2} &\\frac{\\partial x_1}{\\partial q_3} & \\dots &\\frac{\\partial x_1}{\\partial q_n} \\\\ \\frac{\\partial x_2}{\\partial q_1} & \\frac{\\partial x_2}{\\partial q_2} &\\frac{\\partial x_2} {\\partial q_3} & \\dots &\\frac{\\partial x_2}{\\partial q_n} \\\\ \\frac{\\partial x_3}{\\partial q_1} & \\frac{\\partial x_3}{\\partial q_2} &\\frac{\\partial x_3}{\\partial q_3} & \\dots &\\frac{\\partial x_3}{\\partial q_n} \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ \\frac{\\partial x_m}{\\partial q_1} & \\frac{\\partial x_m}{\\partial q_2} &\\frac{\\partial x_m}{\\partial q_3} & \\dots &\\frac{\\partial x_m}{\\partial q_n} \\\\}\\right] \\] Jacobian matrix in robotics : defines the relationship between the joint velocities and the velocity of the TCP: \\[ \\left[\\matrix{\\mathbf{v} \\\\ \\mathbf{\\omega}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\dot{q}} \\] If \\(\\Delta{t}\\) is small enough: $$ \\left[\\matrix{{\\Delta\\mathbf{r}}\\over{\\Delta{t}} \\\\ {\\Delta\\mathbf{\\theta}}\\over{\\Delta{t}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\Delta{q}\\over{\\Delta{t}} $$ Differential inverse kinematics using Jacobian inverse Calculate the difference of the desired and the current position: \\(\\Delta\\mathbf{r} = \\mathbf{r}_{desired} - \\mathbf{r}_0\\) Calculate the rotation between the current orientation and the desired orientation: \\(\\Delta\\mathbf{R} = \\mathbf{R}_{desired}\\mathbf{R}_{0}^{T}\\) , majd konvert\u00e1ljuk \u00e1t axis angle reprezent\u00e1ci\u00f3ba \\((\\mathbf{t},\\phi)\\) Calculate \\(\\Delta\\mathbf{ q}=\\mathbf{J}^{-1}(\\mathbf{q_0})\\cdot \\left[\\matrix{k_1 \\cdot \\Delta\\mathbf{r} \\\\ k_2 \\cdot \\phi \\cdot \\mathbf{t}}\\right]\\) , where the inverse could be substituted by pseudo-inverse or transpose Change joint angles: \\(\\mathbf{q}_{better} = \\mathbf{q}_{0} + \\Delta\\mathbf{q}\\) Practice 1: Install rrr-arm Install dependencies: sudo apt update sudo apt-get install ros-noetic-effort-controllers sudo apt-get install ros-noetic-position-controllers sudo apt-get install ros-noetic-gazebo-ros-pkgs sudo apt-get install ros-noetic-gazebo-ros-control sudo apt-get install ros-noetic-gazebo-ros pip3 install kinpy rosdep update Tip We will use the package kinpy to calculate forward kinematics. Download the source of the package kinpy and study the API: https://pypi.org/project/kinpy/ Clone and build the repo: cd ~/catkin_ws/src git clone https://github.com/Robotawi/rrr-arm.git cd .. catkin build Launch the simulator and move the arm: roslaunch rrr_arm view_arm_gazebo_control_empty_world.launch rostopic pub /rrr_arm/joint1_position_controller/command std_msgs/Float64 \"data: 1.0\" & rostopic pub /rrr_arm/joint2_position_controller/command std_msgs/Float64 \"data: 1.0\" & rostopic pub /rrr_arm/joint3_position_controller/command std_msgs/Float64 \"data: 1.5\" & rostopic pub /rrr_arm/joint4_position_controller/command std_msgs/Float64 \"data: 1.5\" Tip The simulator might raise errors like \"No p gain specified for pid...\", but those can be ignored as won't cause any issues. Build the URDF file describes the robot: cd ~/catkin_ws/src/rrr-arm/urdf rosrun xacro xacro rrr_arm.xacro > rrr_arm.xacro.urdf 2: Move the arm in joint space Create a new file named rrr_arm_node in the scripts folder. Add it to the CMakeLists.txt , as usual. Subscribe to the topic which publishes the joint angles (configuration) of the robot. Create publishers to the 4 topics setting the joint angles of the arm. Use the previous Python scripts as a template. Warning Gazebo and kinpy organized the joints in different orders: 1. [gripper_joint_1, gripper_joint_2, joint_1, joint_2, joint_3, joint_4] - topic /rrr_arm/joint_states - method kp.jacobian.calc_jacobian(...) 2. [joint_1, joint_2, joint_3, joint_4, gripper_joint_1, gripper_joint_2] - method chain.forward_kinematics(...) - method chain.inverse_kinematics(...) Send the arm to the configuration [1.0, 1.0, 1.5, 1.5]. 3. Kinematic task Import kinpy and read the URDF of the robot: import kinpy as kp chain = kp . build_serial_chain_from_urdf ( open ( \"/home/<USERNAME>/catkin_ws/src/rrr-arm/urdf/rrr_arm.xacro.urdf\" ) . read (), \"gripper_frame_cp\" ) print ( chain ) print ( chain . get_joint_parameter_names ()) Calculate the TCP pose in the current configuration using kinpy . The example at https://pypi.org/project/kinpy/ is wrong, use the following example: th1 = np . random . rand ( 2 ) tg = chain . forward_kinematics ( th1 ) th2 = chain . inverse_kinematics ( tg ) self . assertTrue ( np . allclose ( th1 , th2 , atol = 1.0e-6 )) 4: Inverse kinematics using Jacobian inverse Implement a method calculating inverse kinematics using Jacobian inverse for the robot. Ignore the orientation for now. Move the TCP to position (0.59840159, -0.21191189, 0.42244937) . Write a while loop stopping if the length of delta_r is below threshold or rospy.is_shutdown() . Calculate the difference of the desired and current TCP positions ( delta_r ). Scale by constant k_1 . Let phi_dot_t be [0.0, 0.0, 0.0] (ignore the orientation). Concatenate delta_r and phi_dot_t -t. Calculate the Jacobian matrix in the current configuration using the method kp.jacobian.calc_jacobian(...) . Calculate the pseudo inverse of the Jacobian using np.linalg.pinv(...) . Calculate delta_q , use the .dot(...) method from Numpy. Increase the joint angles by delta_q . Bonus exercise: Inverse kinematics with orientation Extend the previous exercise by calculating both the TCP position and orientation. Useful links rrr-arm model https://pypi.org/project/kinpy/ https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation https://www.rosroboticslearning.com/jacobian","title":"7. Kinematics, inverse kinematics"},{"location":"07_robotics_principles/#07-kinematics-inverse-kinematics-programming-a-simulated-robot-in-joint-space-and-task-space","text":"Warning ZH2 (Roslaunch, ROS parameter szerver. ROS service. ROS action. Kinematics, inverse kinematics) and project presentation : December 6.","title":"07. Kinematics, inverse kinematics. Programming a simulated robot in joint space and task space"},{"location":"07_robotics_principles/#rehearsal","text":"","title":"Rehearsal"},{"location":"07_robotics_principles/#3d-transformations","text":"Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters.","title":"3D transformations"},{"location":"07_robotics_principles/#principles-of-robotics","text":"Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques....","title":"Principles of robotics"},{"location":"07_robotics_principles/#lecture","text":"","title":"Lecture"},{"location":"07_robotics_principles/#kinematics-inverse-kinematics","text":"Def. Kinematics Calculation of the pose of the TCP from joint angles. (From joint space to task space) Kinematic model Denavit--Hartenberg (HD) convention URDF (Unified Robotics Description Format, XML-based) If the frames attached to each segment are named \\(base, 1, 2, 3, ..., TCP\\) , transformations between two neighboring segments \\(i\\) and \\(i+1\\) ---dependent on the angle of the joint enclosed by them---are named \\(T_{i+1,i}(q_{i+1})\\) , the transformation from the base frame to the TCP can be calculated as follows for a robot with \\(n\\) joints: \\[ T_{TCP,base}(q_1, \\cdots, q_n) = T_{TCP,n-1}(q_{n}) \\cdot T_{n-1,n-2}(q_{n-1}) \\cdots T_{2,1}(q_2) \\cdot T_{1,base}(q_1) \\cdot base \\] Def. Inverse kinematics Calculation of the joint angles in order to reach desired (or any) TCP pose. (From task space to joint space)","title":"Kinematics, inverse kinematics"},{"location":"07_robotics_principles/#differential-inverse-kinematics","text":"Def. Differential inverse kinematics How to change the joint angles to achieve the desired small change in TCP pose (including rotation and translation). Jacobian matrix (Jacobian): The Jacobian matrix of a vector-valued function of several variables is the matrix of all its first-order partial derivatives. \\[ \\mathbf{J} = \\left[\\matrix{\\frac{\\partial x_1}{\\partial q_1} & \\frac{\\partial x_1}{\\partial q_2} &\\frac{\\partial x_1}{\\partial q_3} & \\dots &\\frac{\\partial x_1}{\\partial q_n} \\\\ \\frac{\\partial x_2}{\\partial q_1} & \\frac{\\partial x_2}{\\partial q_2} &\\frac{\\partial x_2} {\\partial q_3} & \\dots &\\frac{\\partial x_2}{\\partial q_n} \\\\ \\frac{\\partial x_3}{\\partial q_1} & \\frac{\\partial x_3}{\\partial q_2} &\\frac{\\partial x_3}{\\partial q_3} & \\dots &\\frac{\\partial x_3}{\\partial q_n} \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ \\frac{\\partial x_m}{\\partial q_1} & \\frac{\\partial x_m}{\\partial q_2} &\\frac{\\partial x_m}{\\partial q_3} & \\dots &\\frac{\\partial x_m}{\\partial q_n} \\\\}\\right] \\] Jacobian matrix in robotics : defines the relationship between the joint velocities and the velocity of the TCP: \\[ \\left[\\matrix{\\mathbf{v} \\\\ \\mathbf{\\omega}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\dot{q}} \\] If \\(\\Delta{t}\\) is small enough: $$ \\left[\\matrix{{\\Delta\\mathbf{r}}\\over{\\Delta{t}} \\\\ {\\Delta\\mathbf{\\theta}}\\over{\\Delta{t}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\Delta{q}\\over{\\Delta{t}} $$","title":"Differential inverse kinematics"},{"location":"07_robotics_principles/#differential-inverse-kinematics-using-jacobian-inverse","text":"Calculate the difference of the desired and the current position: \\(\\Delta\\mathbf{r} = \\mathbf{r}_{desired} - \\mathbf{r}_0\\) Calculate the rotation between the current orientation and the desired orientation: \\(\\Delta\\mathbf{R} = \\mathbf{R}_{desired}\\mathbf{R}_{0}^{T}\\) , majd konvert\u00e1ljuk \u00e1t axis angle reprezent\u00e1ci\u00f3ba \\((\\mathbf{t},\\phi)\\) Calculate \\(\\Delta\\mathbf{ q}=\\mathbf{J}^{-1}(\\mathbf{q_0})\\cdot \\left[\\matrix{k_1 \\cdot \\Delta\\mathbf{r} \\\\ k_2 \\cdot \\phi \\cdot \\mathbf{t}}\\right]\\) , where the inverse could be substituted by pseudo-inverse or transpose Change joint angles: \\(\\mathbf{q}_{better} = \\mathbf{q}_{0} + \\Delta\\mathbf{q}\\)","title":"Differential inverse kinematics using Jacobian inverse"},{"location":"07_robotics_principles/#practice","text":"","title":"Practice"},{"location":"07_robotics_principles/#1-install-rrr-arm","text":"Install dependencies: sudo apt update sudo apt-get install ros-noetic-effort-controllers sudo apt-get install ros-noetic-position-controllers sudo apt-get install ros-noetic-gazebo-ros-pkgs sudo apt-get install ros-noetic-gazebo-ros-control sudo apt-get install ros-noetic-gazebo-ros pip3 install kinpy rosdep update Tip We will use the package kinpy to calculate forward kinematics. Download the source of the package kinpy and study the API: https://pypi.org/project/kinpy/ Clone and build the repo: cd ~/catkin_ws/src git clone https://github.com/Robotawi/rrr-arm.git cd .. catkin build Launch the simulator and move the arm: roslaunch rrr_arm view_arm_gazebo_control_empty_world.launch rostopic pub /rrr_arm/joint1_position_controller/command std_msgs/Float64 \"data: 1.0\" & rostopic pub /rrr_arm/joint2_position_controller/command std_msgs/Float64 \"data: 1.0\" & rostopic pub /rrr_arm/joint3_position_controller/command std_msgs/Float64 \"data: 1.5\" & rostopic pub /rrr_arm/joint4_position_controller/command std_msgs/Float64 \"data: 1.5\" Tip The simulator might raise errors like \"No p gain specified for pid...\", but those can be ignored as won't cause any issues. Build the URDF file describes the robot: cd ~/catkin_ws/src/rrr-arm/urdf rosrun xacro xacro rrr_arm.xacro > rrr_arm.xacro.urdf","title":"1: Install rrr-arm"},{"location":"07_robotics_principles/#2-move-the-arm-in-joint-space","text":"Create a new file named rrr_arm_node in the scripts folder. Add it to the CMakeLists.txt , as usual. Subscribe to the topic which publishes the joint angles (configuration) of the robot. Create publishers to the 4 topics setting the joint angles of the arm. Use the previous Python scripts as a template. Warning Gazebo and kinpy organized the joints in different orders: 1. [gripper_joint_1, gripper_joint_2, joint_1, joint_2, joint_3, joint_4] - topic /rrr_arm/joint_states - method kp.jacobian.calc_jacobian(...) 2. [joint_1, joint_2, joint_3, joint_4, gripper_joint_1, gripper_joint_2] - method chain.forward_kinematics(...) - method chain.inverse_kinematics(...) Send the arm to the configuration [1.0, 1.0, 1.5, 1.5].","title":"2: Move the arm in joint space"},{"location":"07_robotics_principles/#3-kinematic-task","text":"Import kinpy and read the URDF of the robot: import kinpy as kp chain = kp . build_serial_chain_from_urdf ( open ( \"/home/<USERNAME>/catkin_ws/src/rrr-arm/urdf/rrr_arm.xacro.urdf\" ) . read (), \"gripper_frame_cp\" ) print ( chain ) print ( chain . get_joint_parameter_names ()) Calculate the TCP pose in the current configuration using kinpy . The example at https://pypi.org/project/kinpy/ is wrong, use the following example: th1 = np . random . rand ( 2 ) tg = chain . forward_kinematics ( th1 ) th2 = chain . inverse_kinematics ( tg ) self . assertTrue ( np . allclose ( th1 , th2 , atol = 1.0e-6 ))","title":"3. Kinematic task"},{"location":"07_robotics_principles/#4-inverse-kinematics-using-jacobian-inverse","text":"Implement a method calculating inverse kinematics using Jacobian inverse for the robot. Ignore the orientation for now. Move the TCP to position (0.59840159, -0.21191189, 0.42244937) . Write a while loop stopping if the length of delta_r is below threshold or rospy.is_shutdown() . Calculate the difference of the desired and current TCP positions ( delta_r ). Scale by constant k_1 . Let phi_dot_t be [0.0, 0.0, 0.0] (ignore the orientation). Concatenate delta_r and phi_dot_t -t. Calculate the Jacobian matrix in the current configuration using the method kp.jacobian.calc_jacobian(...) . Calculate the pseudo inverse of the Jacobian using np.linalg.pinv(...) . Calculate delta_q , use the .dot(...) method from Numpy. Increase the joint angles by delta_q .","title":"4: Inverse kinematics using Jacobian inverse"},{"location":"07_robotics_principles/#bonus-exercise-inverse-kinematics-with-orientation","text":"Extend the previous exercise by calculating both the TCP position and orientation.","title":"Bonus exercise: Inverse kinematics with orientation"},{"location":"07_robotics_principles/#useful-links","text":"rrr-arm model https://pypi.org/project/kinpy/ https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation https://www.rosroboticslearning.com/jacobian","title":"Useful links"},{"location":"08_sensory_data/","text":"10. Szenzoros adatok gy\u0171jt\u00e9se \u00e9s feldolgoz\u00e1sa Gyakorlat Thing may change here... Ezt a gyakorlatot lehet, hogy le fogjuk cser\u00e9lni. 1: Leo rover Install\u00e1ljuk a Leo rover ROS package-eit: sudo apt update sudo apt install ros-noetic-leo* A http://wiki.ros.org/leo_gazebo le\u00edr\u00e1s seg\u00edts\u00e9g\u00e9vel ind\u00edtsuk el a gazebo szimul\u00e1tort a Mars landscape-pel. Ind\u00edtsunk teleop node-ot, \u00e9s mozgassuk meg a robotot. 2: K\u00e1v\u00e9 a Marson -- k\u00e9pek r\u00f6gz\u00edt\u00e9se Warning A Mars rover k\u00e9pet k\u00fcld\u00f6tt egy k\u00fcl\u00f6n\u00f6s, k\u00e1v\u00e9s b\u00f6gr\u00e9nek t\u0171n\u0151 t\u00e1rgyr\u00f3l! A feladat, hogy ford\u00edtsuk a rovert a b\u00f6gre fel\u00e9, majd k\u00f6zel\u00edts\u00fck meg, hogy r\u00e9szletesen megvizsg\u00e1lhassuk. Ind\u00edtsuk el a Gazebo-t: gazebo Az insert panelen keress\u00fck ki a googleresearch/models/cole_hardware_mug_classic_blue modellt, majd helyezz\u00fck el a szimul\u00e1ci\u00f3ban. Ez az\u00e9rt kell, hogy k\u00e9s\u0151bb meglegyen a b\u00f6gre modellje a f\u00e1ljrendszer\u00fcnkben. Z\u00e1rjuk be a Gazebo-t T\u00f6lts\u00fck le a leo_masryard_coffee.launch \u00e9s a marsyard_coffe.world f\u00e1jlokat, majd m\u00e1soljuk be rendre a catkin_ws/src/ros_course/launch \u00e9s catkin_ws/src/ros_course/worlds mapp\u00e1kba. A .world f\u00e1jlokban \u00edrjuk \u00e1t a /home/tamas/.ignition/fuel/fuel... el\u00e9r\u00e9si utakat (f\u00e1jlonk\u00e9nt 2x) a saj\u00e1tunkra. Ind\u00edtsuk el a szimul\u00e1tort: roslaunch ros_course leo_marsyard_coffee.launch Ind\u00edtsuk el a teleopot \u00e9s az rqt_image_view -t: rosrun leo_teleop key_teleop ``` ``` bash rosrun rqt_image_view rqt_image_view Tip Ha a szimul\u00e1tor futtat\u00e1sa t\u00fals\u00e1gosan megterhel\u0151 a PC sz\u00e1m\u00e1ra, dolgozhatunk a terrain n\u00e9lk\u00fcli leo_gazebo_coffee.launch \u00e9s gazebo_coffe.world f\u00e1jlokkal is. Ments\u00fcnk le egy-egy k\u00e9pet, amin l\u00e1that\u00f3, illetve nem l\u00e1that\u00f3 a k\u00e1v\u00e9s b\u00f6gre. 3: K\u00e1v\u00e9 a Marson -- offline k\u00e9pfeldolgoz\u00e1s \u00cdrjunk Python szkriptet, amely beolvassa \u00e9s megjelen\u00edti a lementett k\u00e9peket. Sz\u00edn alap\u00fa szegment\u00e1l\u00e1ssal (vagy b\u00e1rhogy m\u00e1shogy) szegment\u00e1ljuk a k\u00e1v\u00e9s b\u00f6gr\u00e9t. Hat\u00e1rozzuk meg a b\u00f6gre k\u00f6z\u00e9ppontj\u00e1t k\u00e9pi koordin\u00e1t\u00e1kban. A szegment\u00e1l\u00e1s zaja gondot okozhat, pr\u00f3b\u00e1ljuk meg lesz\u0171rni. 4: K\u00e1v\u00e9 a Marson -- online perception node Iratkozzunk fel a /camera/image_raw topicra, majd a cv.imshow() f\u00fcggv\u00e9ny seg\u00edts\u00e9g\u00e9val jelen\u00edts\u00fck meg a kapott k\u00e9peket. Dolgozzuk be a m\u0171k\u00f6d\u0151 computer vision algoritmusunkat egy ROS node-ba. Publik\u00e1ljuk \u00faj topicban a detekt\u00e1lt b\u00f6gre k\u00f6z\u00e9ppontj\u00e1nak k\u00e9pi koordin\u00e1t\u00e1t. Haszn\u00e1lhatjuk pl. az Int32MultiArray, Point2D t\u00edpusokat, vagy defini\u00e1lhatunk saj\u00e1tot (k\u00e9s\u0151bb sz\u00fcks\u00e9g lesz a b\u00f6gre m\u00e9ret\u00e9re is). B\u00f3nusz: publik\u00e1ljuk a maszkot \u00e9s a maszkolt k\u00e9pet egy-egy Image topicban 5: K\u00e1v\u00e9 a Marson -- operation logic node \u00cdrjunk \u00faj ROS node-ot, amely fogadja a perception node \u00fczeneteit, illetve k\u00e9pes a rover mozg\u00e1s\u00e1nak ir\u00e1ny\u00edt\u00e1s\u00e1ra. Forgassuk a rovert egy helyben, am\u00edg a b\u00f6gre a k\u00e9p k\u00f6zep\u00e9re nem ker\u00fcl. K\u00f6zel\u00edts\u00fck meg a b\u00f6gr\u00e9t annyira, hogy a l\u00e1tsz\u00f3lagos m\u00e9rete a k\u00e9p m\u00e9ret\u00e9nek 50%-\u00e1t el nem \u00e9ri. Ments\u00fcnk le k\u00e9pet a gyan\u00fas objektumr\u00f3l. 5+1: B\u00f3nusz N\u00e9zz\u00fcnk sz\u00e9t Gazebo-ban a beilleszthet\u0151 modellek k\u00f6z\u00f6tt ( insert panel) \u00e9s v\u00e1lasszunk egyet, amely valamilyen m\u00e1s m\u00f3dszerrel detekt\u00e1lhat\u00f3 a kamera k\u00e9p\u00e9n (pl. template matching). M\u00f3dos\u00edtsuk \u00fagy a node-okat, hogy ezt az objektumot k\u00f6zel\u00edtse meg a rover. Figyelem! Az \u00f3ra v\u00e9g\u00e9n a forr\u00e1sk\u00f3dokat mindenkinek fel kell t\u00f6lteni Moodle-re egy zip arch\u00edvumba csomagolva! Hasznos linkek http://wiki.ros.org/leo_gazebo http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython https://realpython.com/python-opencv-color-spaces/ https://stackoverflow.com/questions/59164192/how-to-find-the-contour-of-a-blob-using-opencv-python","title":"10. Szenzoros adatok gy\u0171jt\u00e9se \u00e9s feldolgoz\u00e1sa"},{"location":"08_sensory_data/#10-szenzoros-adatok-gyujtese-es-feldolgozasa","text":"","title":"10. Szenzoros adatok gy\u0171jt\u00e9se \u00e9s feldolgoz\u00e1sa"},{"location":"08_sensory_data/#gyakorlat","text":"Thing may change here... Ezt a gyakorlatot lehet, hogy le fogjuk cser\u00e9lni.","title":"Gyakorlat"},{"location":"08_sensory_data/#1-leo-rover","text":"Install\u00e1ljuk a Leo rover ROS package-eit: sudo apt update sudo apt install ros-noetic-leo* A http://wiki.ros.org/leo_gazebo le\u00edr\u00e1s seg\u00edts\u00e9g\u00e9vel ind\u00edtsuk el a gazebo szimul\u00e1tort a Mars landscape-pel. Ind\u00edtsunk teleop node-ot, \u00e9s mozgassuk meg a robotot.","title":"1: Leo rover"},{"location":"08_sensory_data/#2-kave-a-marson-kepek-rogzitese","text":"Warning A Mars rover k\u00e9pet k\u00fcld\u00f6tt egy k\u00fcl\u00f6n\u00f6s, k\u00e1v\u00e9s b\u00f6gr\u00e9nek t\u0171n\u0151 t\u00e1rgyr\u00f3l! A feladat, hogy ford\u00edtsuk a rovert a b\u00f6gre fel\u00e9, majd k\u00f6zel\u00edts\u00fck meg, hogy r\u00e9szletesen megvizsg\u00e1lhassuk. Ind\u00edtsuk el a Gazebo-t: gazebo Az insert panelen keress\u00fck ki a googleresearch/models/cole_hardware_mug_classic_blue modellt, majd helyezz\u00fck el a szimul\u00e1ci\u00f3ban. Ez az\u00e9rt kell, hogy k\u00e9s\u0151bb meglegyen a b\u00f6gre modellje a f\u00e1ljrendszer\u00fcnkben. Z\u00e1rjuk be a Gazebo-t T\u00f6lts\u00fck le a leo_masryard_coffee.launch \u00e9s a marsyard_coffe.world f\u00e1jlokat, majd m\u00e1soljuk be rendre a catkin_ws/src/ros_course/launch \u00e9s catkin_ws/src/ros_course/worlds mapp\u00e1kba. A .world f\u00e1jlokban \u00edrjuk \u00e1t a /home/tamas/.ignition/fuel/fuel... el\u00e9r\u00e9si utakat (f\u00e1jlonk\u00e9nt 2x) a saj\u00e1tunkra. Ind\u00edtsuk el a szimul\u00e1tort: roslaunch ros_course leo_marsyard_coffee.launch Ind\u00edtsuk el a teleopot \u00e9s az rqt_image_view -t: rosrun leo_teleop key_teleop ``` ``` bash rosrun rqt_image_view rqt_image_view Tip Ha a szimul\u00e1tor futtat\u00e1sa t\u00fals\u00e1gosan megterhel\u0151 a PC sz\u00e1m\u00e1ra, dolgozhatunk a terrain n\u00e9lk\u00fcli leo_gazebo_coffee.launch \u00e9s gazebo_coffe.world f\u00e1jlokkal is. Ments\u00fcnk le egy-egy k\u00e9pet, amin l\u00e1that\u00f3, illetve nem l\u00e1that\u00f3 a k\u00e1v\u00e9s b\u00f6gre.","title":"2: K\u00e1v\u00e9 a Marson -- k\u00e9pek r\u00f6gz\u00edt\u00e9se"},{"location":"08_sensory_data/#3-kave-a-marson-offline-kepfeldolgozas","text":"\u00cdrjunk Python szkriptet, amely beolvassa \u00e9s megjelen\u00edti a lementett k\u00e9peket. Sz\u00edn alap\u00fa szegment\u00e1l\u00e1ssal (vagy b\u00e1rhogy m\u00e1shogy) szegment\u00e1ljuk a k\u00e1v\u00e9s b\u00f6gr\u00e9t. Hat\u00e1rozzuk meg a b\u00f6gre k\u00f6z\u00e9ppontj\u00e1t k\u00e9pi koordin\u00e1t\u00e1kban. A szegment\u00e1l\u00e1s zaja gondot okozhat, pr\u00f3b\u00e1ljuk meg lesz\u0171rni.","title":"3: K\u00e1v\u00e9 a Marson -- offline k\u00e9pfeldolgoz\u00e1s"},{"location":"08_sensory_data/#4-kave-a-marson-online-perception-node","text":"Iratkozzunk fel a /camera/image_raw topicra, majd a cv.imshow() f\u00fcggv\u00e9ny seg\u00edts\u00e9g\u00e9val jelen\u00edts\u00fck meg a kapott k\u00e9peket. Dolgozzuk be a m\u0171k\u00f6d\u0151 computer vision algoritmusunkat egy ROS node-ba. Publik\u00e1ljuk \u00faj topicban a detekt\u00e1lt b\u00f6gre k\u00f6z\u00e9ppontj\u00e1nak k\u00e9pi koordin\u00e1t\u00e1t. Haszn\u00e1lhatjuk pl. az Int32MultiArray, Point2D t\u00edpusokat, vagy defini\u00e1lhatunk saj\u00e1tot (k\u00e9s\u0151bb sz\u00fcks\u00e9g lesz a b\u00f6gre m\u00e9ret\u00e9re is). B\u00f3nusz: publik\u00e1ljuk a maszkot \u00e9s a maszkolt k\u00e9pet egy-egy Image topicban","title":"4: K\u00e1v\u00e9 a Marson -- online perception node"},{"location":"08_sensory_data/#5-kave-a-marson-operation-logic-node","text":"\u00cdrjunk \u00faj ROS node-ot, amely fogadja a perception node \u00fczeneteit, illetve k\u00e9pes a rover mozg\u00e1s\u00e1nak ir\u00e1ny\u00edt\u00e1s\u00e1ra. Forgassuk a rovert egy helyben, am\u00edg a b\u00f6gre a k\u00e9p k\u00f6zep\u00e9re nem ker\u00fcl. K\u00f6zel\u00edts\u00fck meg a b\u00f6gr\u00e9t annyira, hogy a l\u00e1tsz\u00f3lagos m\u00e9rete a k\u00e9p m\u00e9ret\u00e9nek 50%-\u00e1t el nem \u00e9ri. Ments\u00fcnk le k\u00e9pet a gyan\u00fas objektumr\u00f3l.","title":"5: K\u00e1v\u00e9 a Marson -- operation logic node"},{"location":"08_sensory_data/#51-bonusz","text":"N\u00e9zz\u00fcnk sz\u00e9t Gazebo-ban a beilleszthet\u0151 modellek k\u00f6z\u00f6tt ( insert panel) \u00e9s v\u00e1lasszunk egyet, amely valamilyen m\u00e1s m\u00f3dszerrel detekt\u00e1lhat\u00f3 a kamera k\u00e9p\u00e9n (pl. template matching). M\u00f3dos\u00edtsuk \u00fagy a node-okat, hogy ezt az objektumot k\u00f6zel\u00edtse meg a rover. Figyelem! Az \u00f3ra v\u00e9g\u00e9n a forr\u00e1sk\u00f3dokat mindenkinek fel kell t\u00f6lteni Moodle-re egy zip arch\u00edvumba csomagolva!","title":"5+1: B\u00f3nusz"},{"location":"08_sensory_data/#hasznos-linkek","text":"http://wiki.ros.org/leo_gazebo http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython https://realpython.com/python-opencv-color-spaces/ https://stackoverflow.com/questions/59164192/how-to-find-the-contour-of-a-blob-using-opencv-python","title":"Hasznos linkek"},{"location":"projects/","text":"Projects Challenge levels and grades Projects can be completed at three Challenge levels . The Challenge level determines the best grade that can be received to the project! Challenge level Best grade Basic 3 Advanced 4 Epic 5 Tip The projects are defined in a way that it is recommended to tart with the Basic level, and then gradually work towards Epic . The projects are graded based on the follwoing aspects: Proved to be the student's own work Running results valid output Usage of versioning, usage of GitHub/GitLab/other repository Grading: completeness of the soultion proper ROS communication proper structure of the program quality of implementation documentation quality Schedule Week Date Event 2. szept. 13 Announcement of project topics. 8. okt. 25 Project milestone. 14. nov. 6 Project presentations. Grading Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Jegy = (Test1 + Test2 + 2 \\times Project) / 4\\) Project topics 1. PlatypOUs 1.1. PlatypOUs path following Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system for path follwoing in the simulator, using any sensor of the robot (e.g., driving next to the wall with given distance using LIDAR). Epic: Implementation and testing on the real robot/impress me! 1.2. PlatypOUs obstacle avoidance Basic: SSimulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system to detect obstacle. Calculation and execution of a trajectory avoiding the obstacle in the simulator, using any sensor of the robot. Epic: Implementation and testing on the real robot/impress me! 1.3. PlatypOUs object follwoing Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system to detect an object and follow it in the simulator, using any sensor of the robot(e.g., visual servoing). Epic: Implementation and testing on the real robot/impress me! 1.4. PlatypOUs action library Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS action library containing simple actions and their execution (e.g., push object, move to object, turn around). Epic: Implementation and testing on the real robot/impress me! 2. AMBF 2.1. ROS of a da Vinci robot in the AMBF simulator Basic: Simulator setup, controlling the robot in joint space and task space (IK is implemented in AMBF) from ROS using the topic from CRTK. Advanced: Object detection in the Peg transfer puzzle . Epic: Autonomous manipulation in Peg transfer /implress me! 2.2. ROS integration of a KUKA robot in the AMBF simulator Basic: Simulator setup, controlling the robot in joint space from ROS. Advanced: Controlling the robot in task space, IK. Epic: Trajectory planning. 2.3. ROS integration of a PR2 humanoid robot in the AMBF simulator Basic: Simulator setup, controlling the robot in joint space from ROS. Advanced: Controlling the robot in task space, IK. Epic: Trajectory planning/Navigation/Manipulation. X. Custom topic Based on discussion. Links Gazebo ROS packages PlatypOUs AMBF My fork of AMBF CRTK topics Navigation stack Paper on LiDAR SLAM Paper on vSLAM Paper on Visual Servoing Mobile Robot","title":"Projects"},{"location":"projects/#projects","text":"","title":"Projects"},{"location":"projects/#challenge-levels-and-grades","text":"Projects can be completed at three Challenge levels . The Challenge level determines the best grade that can be received to the project! Challenge level Best grade Basic 3 Advanced 4 Epic 5 Tip The projects are defined in a way that it is recommended to tart with the Basic level, and then gradually work towards Epic . The projects are graded based on the follwoing aspects: Proved to be the student's own work Running results valid output Usage of versioning, usage of GitHub/GitLab/other repository Grading: completeness of the soultion proper ROS communication proper structure of the program quality of implementation documentation quality","title":"Challenge levels and grades"},{"location":"projects/#schedule","text":"Week Date Event 2. szept. 13 Announcement of project topics. 8. okt. 25 Project milestone. 14. nov. 6 Project presentations.","title":"Schedule"},{"location":"projects/#grading","text":"Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Jegy = (Test1 + Test2 + 2 \\times Project) / 4\\)","title":"Grading"},{"location":"projects/#project-topics","text":"","title":"Project topics"},{"location":"projects/#1-platypous","text":"","title":"1. PlatypOUs"},{"location":"projects/#11-platypous-path-following","text":"Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system for path follwoing in the simulator, using any sensor of the robot (e.g., driving next to the wall with given distance using LIDAR). Epic: Implementation and testing on the real robot/impress me!","title":"1.1. PlatypOUs path following"},{"location":"projects/#12-platypous-obstacle-avoidance","text":"Basic: SSimulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system to detect obstacle. Calculation and execution of a trajectory avoiding the obstacle in the simulator, using any sensor of the robot. Epic: Implementation and testing on the real robot/impress me!","title":"1.2. PlatypOUs obstacle avoidance"},{"location":"projects/#13-platypous-object-follwoing","text":"Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS system to detect an object and follow it in the simulator, using any sensor of the robot(e.g., visual servoing). Epic: Implementation and testing on the real robot/impress me!","title":"1.3. PlatypOUs object follwoing"},{"location":"projects/#14-platypous-action-library","text":"Basic: Simulator setup, testing SLAM. Implementation of ROS node(s) to read the sensor data and move the robot. Advanced: Implementation of a ROS action library containing simple actions and their execution (e.g., push object, move to object, turn around). Epic: Implementation and testing on the real robot/impress me!","title":"1.4. PlatypOUs action library"},{"location":"projects/#2-ambf","text":"","title":"2. AMBF"},{"location":"projects/#21-ros-of-a-da-vinci-robot-in-the-ambf-simulator","text":"Basic: Simulator setup, controlling the robot in joint space and task space (IK is implemented in AMBF) from ROS using the topic from CRTK. Advanced: Object detection in the Peg transfer puzzle . Epic: Autonomous manipulation in Peg transfer /implress me!","title":"2.1. ROS of a da Vinci robot in the AMBF simulator"},{"location":"projects/#22-ros-integration-of-a-kuka-robot-in-the-ambf-simulator","text":"Basic: Simulator setup, controlling the robot in joint space from ROS. Advanced: Controlling the robot in task space, IK. Epic: Trajectory planning.","title":"2.2. ROS integration of a KUKA robot in the AMBF simulator"},{"location":"projects/#23-ros-integration-of-a-pr2-humanoid-robot-in-the-ambf-simulator","text":"Basic: Simulator setup, controlling the robot in joint space from ROS. Advanced: Controlling the robot in task space, IK. Epic: Trajectory planning/Navigation/Manipulation.","title":"2.3. ROS integration of a PR2 humanoid robot in the AMBF simulator"},{"location":"projects/#x-custom-topic","text":"Based on discussion.","title":"X. Custom topic"},{"location":"projects/#links","text":"Gazebo ROS packages PlatypOUs AMBF My fork of AMBF CRTK topics Navigation stack Paper on LiDAR SLAM Paper on vSLAM Paper on Visual Servoing Mobile Robot","title":"Links"}]}